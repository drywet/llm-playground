{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "7m8qC1ztm6s-"
      },
      "source": [
        "# Fine-Tune a Generative AI Model for Dialogue Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "%pip install --upgrade pip\n",
        "%pip install torch torchdata"
      ],
      "metadata": {
        "id": "mKOW8M5Mm6tC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "UN5vSWGpm6tE"
      },
      "outputs": [],
      "source": [
        "%pip install transformers datasets evaluate rouge_score loralib peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:49:01.390956300Z",
          "start_time": "2023-07-07T12:48:54.306975700Z"
        },
        "id": "yqQUz0XPm6tF"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoModelForCausalLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
        "import torch\n",
        "import time\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:49:03.211458900Z",
          "start_time": "2023-07-07T12:49:01.390956300Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "a80a5944e70b47998d8c2c69d507921a",
            "6dac7c8662d04bb4974f6157fe68427a",
            "11fad3b120ba455fb5b5ecba576e3a8f",
            "93b879cce4c24f00a0de09ae8c1feced",
            "3bb5513122d14d5396f7074b824402f2",
            "d463498bbb7f47deacc5d628ddf9dd5b",
            "6148f855b94b46dc9b4eff88c3652667",
            "98212a0d70a847b1a38f4f86efef6de8",
            "b85fe06196784b1e8cbb69cb65086104",
            "06fd29c11bb54b23acd134d5ca525ab6",
            "5ceea9750bb841c5b6913ad2eeaf2c4e"
          ]
        },
        "id": "8vqGgQl6m6tF",
        "outputId": "37dd4c8b-f3b8-44a5-e787-2493d00c1aeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c07c4cf4362c223c/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a80a5944e70b47998d8c2c69d507921a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 12460\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 1500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "\n",
        "dataset = load_dataset(huggingface_dataset_name)\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "# %pip3 install torch --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-07-07T12:49:18.087557Z",
          "start_time": "2023-07-07T12:49:18.031742500Z"
        },
        "id": "bUTZ1SWjm6tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numba import cuda\n",
        "device = cuda.get_current_device()\n",
        "device.reset()\n",
        "cuda.close()\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "sSpAcscR72xU",
        "outputId": "51803b8a-17e4-40ca-9aca-1d5b8ddc523e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --gpu-reset"
      ],
      "metadata": {
        "id": "8i2ocRQkhMIP",
        "outputId": "fab784b8-3eef-4b96-d45b-9a502fa5c3d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 00000000:00:04.0 is currently in use by another process.\n",
            "\n",
            "1 device is currently being used by one or more other processes (e.g., Fabric Manager, CUDA application, graphics application such as an X server, or a monitoring application such as another instance of nvidia-smi). Please first kill all processes using this device and all compute applications running in the system.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import gc\n",
        "# gc.collect()"
      ],
      "metadata": {
        "id": "1ZGCUkFp9WVe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:49:18.031742500Z",
          "start_time": "2023-07-07T12:49:02.852069300Z"
        },
        "id": "d1rknWonm6tG"
      },
      "outputs": [],
      "source": [
        "model_name='google/flan-t5-base'\n",
        "\n",
        "device = torch.device('cuda')\n",
        "\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16).cuda()\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:49:18.087557Z",
          "start_time": "2023-07-07T12:49:18.031742500Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-U0-ul_m6tH",
        "outputId": "486cfde5-5a2a-4f51-deaa-682a06bba41f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable model parameters: 247577856\n",
            "all model parameters: 247577856\n",
            "percentage of trainable model parameters: 100.00%\n"
          ]
        }
      ],
      "source": [
        "def print_number_of_trainable_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "print(print_number_of_trainable_model_parameters(original_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:49:57.227008600Z",
          "start_time": "2023-07-07T12:49:18.040664800Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSTAtelem6tI",
        "outputId": "c1616205-e5dd-477b-ebb6-d8eb6068d2b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Summarize the following conversation.\n",
            "\n",
            "#Person1#: Have you considered upgrading your system?\n",
            "#Person2#: Yes, but I'm not sure what exactly I would need.\n",
            "#Person1#: You could consider adding a painting program to your software. It would allow you to make up your own flyers and banners for advertising.\n",
            "#Person2#: That would be a definite bonus.\n",
            "#Person1#: You might also want to upgrade your hardware because it is pretty outdated now.\n",
            "#Person2#: How can we do that?\n",
            "#Person1#: You'd probably need a faster processor, to begin with. And you also need a more powerful hard disc, more memory and a faster modem. Do you have a CD-ROM drive?\n",
            "#Person2#: No.\n",
            "#Person1#: Then you might want to add a CD-ROM drive too, because most new software programs are coming out on Cds.\n",
            "#Person2#: That sounds great. Thanks.\n",
            "\n",
            "Summary:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "You might want to upgrade your computer.\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "\n",
        "index = 200\n",
        "\n",
        "dialogue = dataset['test'][index]['dialogue']\n",
        "summary = dataset['test'][index]['summary']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "output = tokenizer.decode(\n",
        "    original_model.generate(\n",
        "        inputs[\"input_ids\"].cuda(),\n",
        "        max_new_tokens=200,\n",
        "        # temperature=3,\n",
        "    )[0],\n",
        "    skip_special_tokens=True\n",
        ")\n",
        "\n",
        "dash_line = '-'.join('' for x in range(100))\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix Colab locale\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "dfzyUyvFi1C0"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "oSWKH_7-_Bnl",
        "outputId": "bfd66ce7-4a1a-497c-f3ef-e06e493b21e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jul  7 19:23:39 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    55W / 400W |   7525MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:49:58.398626400Z",
          "start_time": "2023-07-07T12:49:57.227008600Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52,
          "referenced_widgets": [
            "f1905cbfeba94648a6816ccdcda2539d",
            "10120c8d4f7747489b8bee628a6f0180",
            "3e7c8e3218a944c0ac5021caaefdb3e3",
            "6a1a33a0d7604720896e567fa2c36da9",
            "d6c48827c43b491194074d2d10e07ff3",
            "846a9f9375714f8bb3947d38043e57b2",
            "9b316cc6529d461ca32abb338ec28c79",
            "2df8a35554ac42e58c86e933004dd89a",
            "19b8ca77eb1148c99a6c9e162971c75b",
            "6806574fdfd142218e10aa8f0af9f6df",
            "3dacaf711bfe4e78aefc6b9068aead27"
          ]
        },
        "id": "Th-Fr5lcm6tJ",
        "outputId": "955dad6e-3efe-4850-d6f1-bf12e7cb887f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c07c4cf4362c223c/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-c4524df1122f0439.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1905cbfeba94648a6816ccdcda2539d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/knkarthick___csv/knkarthick--dialogsum-c07c4cf4362c223c/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-3365e3168a193577.arrow\n"
          ]
        }
      ],
      "source": [
        "# Preprocess the dataset\n",
        "\n",
        "def tokenize_function(example):\n",
        "    start_prompt = 'Summarize the following conversation.\\n\\n'\n",
        "    end_prompt = '\\n\\nSummary: '\n",
        "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"dialogue\"]]\n",
        "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids.cuda()\n",
        "    example['labels'] = tokenizer(example[\"summary\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids.cuda()\n",
        "\n",
        "    return example\n",
        "\n",
        "# The dataset actually contains 3 diff splits: train, validation, test.\n",
        "# The tokenize_function code is handling all data across all splits in batches.\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['id', 'topic', 'dialogue', 'summary',])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:49:59.501441900Z",
          "start_time": "2023-07-07T12:49:58.402626300Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "c5e8bdb631104c33819e67c1ee42a518",
            "0eed6a8588af41de9ec91529c13b632f",
            "321855886b85445d9265ee49f2355001",
            "294002bae48d44598a363feefcb8ca0f",
            "138c7319791e40ecb395946335750273",
            "e927e12403de49d2987b698c09015fe0",
            "d85dcc81576c4c8daa7937c7ea0ccd74",
            "c479f85c004f4cba9d4263d1e6a4f728",
            "8f4f2adc3c7247b7b1e5683fd9662358",
            "ca983f28c718468c8a1460f4a9515069",
            "c2bba51ae57246ad8ddb69a84de6d400"
          ]
        },
        "id": "ieGfDS67m6tK",
        "outputId": "81c5104d-971c-436b-fe2b-f1dad59499ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5e8bdb631104c33819e67c1ee42a518"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_datasets = tokenized_datasets.filter(lambda example, index: index % 50 == 0, with_indices=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:49:59.523148600Z",
          "start_time": "2023-07-07T12:49:59.506449900Z"
        },
        "id": "gbEkw43om6tK"
      },
      "outputs": [],
      "source": [
        "print(f\"Shapes of the datasets:\")\n",
        "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
        "print(f\"Validation: {tokenized_datasets['validation'].shape}\")\n",
        "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
        "\n",
        "print(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:49:59.626301900Z",
          "start_time": "2023-07-07T12:49:59.528149400Z"
        },
        "id": "k4LtN_2Bm6tL"
      },
      "outputs": [],
      "source": [
        "output_dir = f'../tmp/dialogue-summary-training-{str(int(time.time()))}'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    learning_rate=1e-5,\n",
        "    # num_train_epochs=1,\n",
        "    # per_device_train_batch_size = 8,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=1,\n",
        "    max_steps=2000,\n",
        "    # load_best_model_at_end=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100\n",
        ")\n",
        "\n",
        "from transformers import PrinterCallback, EarlyStoppingCallback, DefaultFlowCallback\n",
        "# callback = PrinterCallback()\n",
        "# callback = EarlyStoppingCallback()\n",
        "# callback = DefaultFlowCallback()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=original_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation']\n",
        "    # callbacks=[callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "EX45_ZwKm6tL"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.state.log_history[0]"
      ],
      "metadata": {
        "id": "MPE4Q-hRrclX",
        "outputId": "822ec909-5667-419c-cacd-3a5415864f07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 48.5, 'learning_rate': 9.995000000000002e-06, 'epoch': 0.0, 'step': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from vega_datasets import data\n",
        "# stocks = data.stocks()\n",
        "\n",
        "trainer_log = pd.DataFrame(trainer.state.log_history)\n",
        "trainer_log = trainer_log[(trainer_log[\"step\"] % 100 == 0) & trainer_log[\"eval_loss\"].notnull()]\n",
        "\n",
        "trainer_log"
      ],
      "metadata": {
        "id": "JGeOrSP4sJqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import altair as alt\n",
        "alt.Chart(trainer_log).mark_line().encode(\n",
        "  x='step',\n",
        "  y='eval_loss'\n",
        ").interactive(bind_y=False)"
      ],
      "metadata": {
        "id": "L_kA13Wiw4GP",
        "outputId": "3ec23f99-87cd-43dc-9371-761c957f5d92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<div id=\"altair-viz-1537816d17d24ead942c52ef0f83e576\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-1537816d17d24ead942c52ef0f83e576\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-1537816d17d24ead942c52ef0f83e576\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-2385c572cdd56adfecb3e281f64b221f\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"field\": \"step\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"eval_loss\", \"type\": \"quantitative\"}}, \"selection\": {\"selector014\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\"]}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-2385c572cdd56adfecb3e281f64b221f\": [{\"loss\": null, \"learning_rate\": null, \"epoch\": 0.06, \"step\": 100, \"eval_loss\": 47.36000061035156, \"eval_runtime\": 3.2528, \"eval_samples_per_second\": 153.716, \"eval_steps_per_second\": 19.368, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.13, \"step\": 200, \"eval_loss\": 42.88199996948242, \"eval_runtime\": 3.2515, \"eval_samples_per_second\": 153.776, \"eval_steps_per_second\": 19.376, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.19, \"step\": 300, \"eval_loss\": 39.55400085449219, \"eval_runtime\": 3.2484, \"eval_samples_per_second\": 153.92, \"eval_steps_per_second\": 19.394, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.26, \"step\": 400, \"eval_loss\": 37.0359992980957, \"eval_runtime\": 3.2483, \"eval_samples_per_second\": 153.924, \"eval_steps_per_second\": 19.394, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.32, \"step\": 500, \"eval_loss\": 35.077999114990234, \"eval_runtime\": 3.2535, \"eval_samples_per_second\": 153.681, \"eval_steps_per_second\": 19.364, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.39, \"step\": 600, \"eval_loss\": 33.683998107910156, \"eval_runtime\": 3.2591, \"eval_samples_per_second\": 153.417, \"eval_steps_per_second\": 19.33, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.45, \"step\": 700, \"eval_loss\": 32.63999938964844, \"eval_runtime\": 3.2475, \"eval_samples_per_second\": 153.963, \"eval_steps_per_second\": 19.399, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.51, \"step\": 800, \"eval_loss\": 32.053001403808594, \"eval_runtime\": 3.2497, \"eval_samples_per_second\": 153.862, \"eval_steps_per_second\": 19.387, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.58, \"step\": 900, \"eval_loss\": 31.677000045776367, \"eval_runtime\": 3.2531, \"eval_samples_per_second\": 153.701, \"eval_steps_per_second\": 19.366, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.64, \"step\": 1000, \"eval_loss\": 31.437999725341797, \"eval_runtime\": 3.2505, \"eval_samples_per_second\": 153.822, \"eval_steps_per_second\": 19.382, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.71, \"step\": 1100, \"eval_loss\": 31.20400047302246, \"eval_runtime\": 3.2496, \"eval_samples_per_second\": 153.865, \"eval_steps_per_second\": 19.387, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.77, \"step\": 1200, \"eval_loss\": 30.958999633789062, \"eval_runtime\": 3.2471, \"eval_samples_per_second\": 153.982, \"eval_steps_per_second\": 19.402, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.83, \"step\": 1300, \"eval_loss\": 30.89900016784668, \"eval_runtime\": 3.248, \"eval_samples_per_second\": 153.939, \"eval_steps_per_second\": 19.396, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.9, \"step\": 1400, \"eval_loss\": 30.777999877929688, \"eval_runtime\": 3.2526, \"eval_samples_per_second\": 153.723, \"eval_steps_per_second\": 19.369, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 0.96, \"step\": 1500, \"eval_loss\": 30.722999572753906, \"eval_runtime\": 3.2473, \"eval_samples_per_second\": 153.975, \"eval_steps_per_second\": 19.401, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.03, \"step\": 1600, \"eval_loss\": 30.656999588012695, \"eval_runtime\": 3.25, \"eval_samples_per_second\": 153.848, \"eval_steps_per_second\": 19.385, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.09, \"step\": 1700, \"eval_loss\": 30.6299991607666, \"eval_runtime\": 3.2508, \"eval_samples_per_second\": 153.808, \"eval_steps_per_second\": 19.38, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.16, \"step\": 1800, \"eval_loss\": 30.632999420166016, \"eval_runtime\": 3.2511, \"eval_samples_per_second\": 153.794, \"eval_steps_per_second\": 19.378, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.22, \"step\": 1900, \"eval_loss\": 30.6200008392334, \"eval_runtime\": 3.2541, \"eval_samples_per_second\": 153.653, \"eval_steps_per_second\": 19.36, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.28, \"step\": 2000, \"eval_loss\": 30.615999221801758, \"eval_runtime\": 3.2504, \"eval_samples_per_second\": 153.825, \"eval_steps_per_second\": 19.382, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.35, \"step\": 2100, \"eval_loss\": 30.600000381469727, \"eval_runtime\": 3.2484, \"eval_samples_per_second\": 153.92, \"eval_steps_per_second\": 19.394, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.41, \"step\": 2200, \"eval_loss\": 30.59600067138672, \"eval_runtime\": 3.2461, \"eval_samples_per_second\": 154.029, \"eval_steps_per_second\": 19.408, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.48, \"step\": 2300, \"eval_loss\": 30.601999282836914, \"eval_runtime\": 3.25, \"eval_samples_per_second\": 153.847, \"eval_steps_per_second\": 19.385, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.54, \"step\": 2400, \"eval_loss\": 30.583999633789062, \"eval_runtime\": 3.2512, \"eval_samples_per_second\": 153.787, \"eval_steps_per_second\": 19.377, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.6, \"step\": 2500, \"eval_loss\": 30.583999633789062, \"eval_runtime\": 3.2499, \"eval_samples_per_second\": 153.849, \"eval_steps_per_second\": 19.385, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.67, \"step\": 2600, \"eval_loss\": 30.583999633789062, \"eval_runtime\": 3.2498, \"eval_samples_per_second\": 153.854, \"eval_steps_per_second\": 19.386, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.73, \"step\": 2700, \"eval_loss\": 30.572999954223633, \"eval_runtime\": 3.2502, \"eval_samples_per_second\": 153.837, \"eval_steps_per_second\": 19.383, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.8, \"step\": 2800, \"eval_loss\": 30.577999114990234, \"eval_runtime\": 3.2514, \"eval_samples_per_second\": 153.78, \"eval_steps_per_second\": 19.376, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.86, \"step\": 2900, \"eval_loss\": 30.566999435424805, \"eval_runtime\": 3.252, \"eval_samples_per_second\": 153.754, \"eval_steps_per_second\": 19.373, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.93, \"step\": 3000, \"eval_loss\": 30.56800079345703, \"eval_runtime\": 3.2499, \"eval_samples_per_second\": 153.849, \"eval_steps_per_second\": 19.385, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 1.99, \"step\": 3100, \"eval_loss\": 30.56599998474121, \"eval_runtime\": 3.2506, \"eval_samples_per_second\": 153.817, \"eval_steps_per_second\": 19.381, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.05, \"step\": 3200, \"eval_loss\": 30.56599998474121, \"eval_runtime\": 3.2502, \"eval_samples_per_second\": 153.835, \"eval_steps_per_second\": 19.383, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.12, \"step\": 3300, \"eval_loss\": 30.56599998474121, \"eval_runtime\": 3.2494, \"eval_samples_per_second\": 153.872, \"eval_steps_per_second\": 19.388, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.18, \"step\": 3400, \"eval_loss\": 30.56800079345703, \"eval_runtime\": 3.2492, \"eval_samples_per_second\": 153.886, \"eval_steps_per_second\": 19.39, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.25, \"step\": 3500, \"eval_loss\": 30.56399917602539, \"eval_runtime\": 3.2531, \"eval_samples_per_second\": 153.701, \"eval_steps_per_second\": 19.366, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.31, \"step\": 3600, \"eval_loss\": 30.56399917602539, \"eval_runtime\": 3.2513, \"eval_samples_per_second\": 153.786, \"eval_steps_per_second\": 19.377, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.37, \"step\": 3700, \"eval_loss\": 30.56399917602539, \"eval_runtime\": 3.2509, \"eval_samples_per_second\": 153.806, \"eval_steps_per_second\": 19.38, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.44, \"step\": 3800, \"eval_loss\": 30.57200050354004, \"eval_runtime\": 3.2495, \"eval_samples_per_second\": 153.872, \"eval_steps_per_second\": 19.388, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.5, \"step\": 3900, \"eval_loss\": 30.56599998474121, \"eval_runtime\": 3.2515, \"eval_samples_per_second\": 153.777, \"eval_steps_per_second\": 19.376, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.57, \"step\": 4000, \"eval_loss\": 30.56800079345703, \"eval_runtime\": 3.2516, \"eval_samples_per_second\": 153.771, \"eval_steps_per_second\": 19.375, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.63, \"step\": 4100, \"eval_loss\": 30.56399917602539, \"eval_runtime\": 3.2502, \"eval_samples_per_second\": 153.835, \"eval_steps_per_second\": 19.383, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.7, \"step\": 4200, \"eval_loss\": 30.56800079345703, \"eval_runtime\": 3.2496, \"eval_samples_per_second\": 153.865, \"eval_steps_per_second\": 19.387, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.76, \"step\": 4300, \"eval_loss\": 30.56999969482422, \"eval_runtime\": 3.2509, \"eval_samples_per_second\": 153.804, \"eval_steps_per_second\": 19.379, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.82, \"step\": 4400, \"eval_loss\": 30.56800079345703, \"eval_runtime\": 3.2497, \"eval_samples_per_second\": 153.859, \"eval_steps_per_second\": 19.386, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.89, \"step\": 4500, \"eval_loss\": 30.56599998474121, \"eval_runtime\": 3.2528, \"eval_samples_per_second\": 153.713, \"eval_steps_per_second\": 19.368, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 2.95, \"step\": 4600, \"eval_loss\": 30.56999969482422, \"eval_runtime\": 3.254, \"eval_samples_per_second\": 153.657, \"eval_steps_per_second\": 19.361, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.02, \"step\": 4700, \"eval_loss\": 30.56599998474121, \"eval_runtime\": 3.2477, \"eval_samples_per_second\": 153.954, \"eval_steps_per_second\": 19.398, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.08, \"step\": 4800, \"eval_loss\": 30.56999969482422, \"eval_runtime\": 3.2523, \"eval_samples_per_second\": 153.739, \"eval_steps_per_second\": 19.371, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.15, \"step\": 4900, \"eval_loss\": 30.56800079345703, \"eval_runtime\": 3.2564, \"eval_samples_per_second\": 153.545, \"eval_steps_per_second\": 19.347, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.21, \"step\": 5000, \"eval_loss\": 30.56399917602539, \"eval_runtime\": 3.2522, \"eval_samples_per_second\": 153.74, \"eval_steps_per_second\": 19.371, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.27, \"step\": 5100, \"eval_loss\": 30.56399917602539, \"eval_runtime\": 3.254, \"eval_samples_per_second\": 153.658, \"eval_steps_per_second\": 19.361, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.34, \"step\": 5200, \"eval_loss\": 30.56999969482422, \"eval_runtime\": 3.2504, \"eval_samples_per_second\": 153.827, \"eval_steps_per_second\": 19.382, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.4, \"step\": 5300, \"eval_loss\": 30.56800079345703, \"eval_runtime\": 3.2472, \"eval_samples_per_second\": 153.979, \"eval_steps_per_second\": 19.401, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.47, \"step\": 5400, \"eval_loss\": 30.56800079345703, \"eval_runtime\": 3.2537, \"eval_samples_per_second\": 153.671, \"eval_steps_per_second\": 19.363, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.53, \"step\": 5500, \"eval_loss\": 30.56399917602539, \"eval_runtime\": 3.249, \"eval_samples_per_second\": 153.894, \"eval_steps_per_second\": 19.391, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.59, \"step\": 5600, \"eval_loss\": 30.56999969482422, \"eval_runtime\": 3.2479, \"eval_samples_per_second\": 153.947, \"eval_steps_per_second\": 19.397, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.66, \"step\": 5700, \"eval_loss\": 30.57200050354004, \"eval_runtime\": 3.2481, \"eval_samples_per_second\": 153.937, \"eval_steps_per_second\": 19.396, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.72, \"step\": 5800, \"eval_loss\": 30.56399917602539, \"eval_runtime\": 3.2531, \"eval_samples_per_second\": 153.697, \"eval_steps_per_second\": 19.366, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.79, \"step\": 5900, \"eval_loss\": 30.56999969482422, \"eval_runtime\": 3.2508, \"eval_samples_per_second\": 153.807, \"eval_steps_per_second\": 19.38, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}, {\"loss\": null, \"learning_rate\": null, \"epoch\": 3.85, \"step\": 6000, \"eval_loss\": 30.56999969482422, \"eval_runtime\": 3.2498, \"eval_samples_per_second\": 153.854, \"eval_steps_per_second\": 19.386, \"train_runtime\": null, \"train_samples_per_second\": null, \"train_steps_per_second\": null, \"total_flos\": null, \"train_loss\": null}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "eval_loss stopped decreasing approximately: after (dataset length / batch size) steps, i.e. after (12460 / 8 = 1557.5) steps"
      ],
      "metadata": {
        "id": "B7HXn0AbyK8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "yvuI0Kso5zRg",
        "outputId": "92c61fc7-68d9-4a67-8417-c568e20c5837",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jul  7 19:22:46 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    56W / 400W |   7517MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abb_KDiGm6tL"
      },
      "source": [
        "Training a fully fine-tuned version of the model would take a few hours on a GPU. To save time, download a checkpoint of the fully fine-tuned model to use in the rest of this notebook. This fully fine-tuned model will also be referred to as the **instruct model** in this lab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:54:39.204106300Z",
          "start_time": "2023-07-07T12:49:59.584722Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0OHDfQrm6tL",
        "outputId": "779279c0-bdaa-4107-ad95-7403d60eb02f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 142 Bytes/2.8 GiB (1.5 KiB/s) with 8 file(s) remaining\rdownload: s3://colab-playground/models/flan-dialogue-summary-checkpoint/generation_config.json to ../tmp/flan-dialogue-summary-checkpoint/generation_config.json\n",
            "Completed 142 Bytes/2.8 GiB (1.5 KiB/s) with 7 file(s) remaining\rCompleted 9.8 KiB/2.8 GiB (77.3 KiB/s) with 7 file(s) remaining \rdownload: s3://colab-playground/models/flan-dialogue-summary-checkpoint/trainer_state.json to ../tmp/flan-dialogue-summary-checkpoint/trainer_state.json\n",
            "Completed 9.8 KiB/2.8 GiB (77.3 KiB/s) with 6 file(s) remaining\rCompleted 11.3 KiB/2.8 GiB (84.1 KiB/s) with 6 file(s) remaining\rdownload: s3://colab-playground/models/flan-dialogue-summary-checkpoint/config.json to ../tmp/flan-dialogue-summary-checkpoint/config.json\n",
            "Completed 11.3 KiB/2.8 GiB (84.1 KiB/s) with 5 file(s) remaining\rCompleted 11.9 KiB/2.8 GiB (78.4 KiB/s) with 5 file(s) remaining\rdownload: s3://colab-playground/models/flan-dialogue-summary-checkpoint/scheduler.pt to ../tmp/flan-dialogue-summary-checkpoint/scheduler.pt\n",
            "Completed 11.9 KiB/2.8 GiB (78.4 KiB/s) with 4 file(s) remaining\rCompleted 26.1 KiB/2.8 GiB (159.5 KiB/s) with 4 file(s) remaining\rdownload: s3://colab-playground/models/flan-dialogue-summary-checkpoint/rng_state.pth to ../tmp/flan-dialogue-summary-checkpoint/rng_state.pth\n",
            "download: s3://colab-playground/models/flan-dialogue-summary-checkpoint/training_args.bin to ../tmp/flan-dialogue-summary-checkpoint/training_args.bin\n",
            "download: s3://colab-playground/models/flan-dialogue-summary-checkpoint/pytorch_model.bin to ../tmp/flan-dialogue-summary-checkpoint/pytorch_model.bin\n",
            "download: s3://colab-playground/models/flan-dialogue-summary-checkpoint/optimizer.pt to ../tmp/flan-dialogue-summary-checkpoint/optimizer.pt\n"
          ]
        }
      ],
      "source": [
        "!aws s3 cp --recursive s3://colab-playground/models/flan-dialogue-summary-checkpoint/ ../tmp/flan-dialogue-summary-checkpoint/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "HtKtoqGGm6tL"
      },
      "source": [
        "The size of the downloaded instruct model is approximately 1GB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:55:05.180428700Z",
          "start_time": "2023-07-07T12:55:05.076711800Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRLyTVo_m6tM",
        "outputId": "29e35d2c-f4f6-4070-bcce-f512792fa2a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 945M Jul  7 12:35 ../tmp/flan-dialogue-summary-checkpoint/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "!ls -alh ../tmp/flan-dialogue-summary-checkpoint/pytorch_model.bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:56:25.003233500Z",
          "start_time": "2023-07-07T12:56:12.943640200Z"
        },
        "id": "M83XNso3m6tM"
      },
      "outputs": [],
      "source": [
        "instruct_model = AutoModelForSeq2SeqLM.from_pretrained(\"../tmp/flan-dialogue-summary-checkpoint\", torch_dtype=torch.bfloat16).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T12:57:47.125989500Z",
          "start_time": "2023-07-07T12:56:31.115502800Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLkw4Y9Am6tM",
        "outputId": "5ca37a9a-c6f5-4e20-c420-b73776eb6195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# teaches #Person2# how to upgrade software and hardware in #Person2#'s system.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "ORIGINAL MODEL:\n",
            "You might want to upgrade your computer.\n",
            "---------------------------------------------------------------------------------------------------\n",
            "INSTRUCT MODEL:\n",
            "#Person1# suggests #Person2# upgrading #Person2#'s system, hardware, and CD-ROM drive. #Person2# thinks it's great.\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the Model Qualitatively (Human Evaluation)\n",
        "\n",
        "index = 200\n",
        "dialogue = dataset['test'][index]['dialogue']\n",
        "human_baseline_summary = dataset['test'][index]['summary']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "\"\"\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
        "\n",
        "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
        "print(dash_line)\n",
        "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T13:00:16.131951700Z",
          "start_time": "2023-07-07T13:00:13.912040400Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "51e9c784a63744468d400699f01ded6c",
            "b95c132c45954556958b01c44dc2b92a",
            "dca1e8e2c5f543fbb80abca2b8810c2b",
            "c5608521c86b48138969e037d8e73b2b",
            "ac70795e1b0e413787935c111bfad60f",
            "363ce6cf8f9a4dc2abf6819fe889d77c",
            "0eef781b94df4adbb8b8cffbeb9814da",
            "c38b56d469e549b7932e10fad13e109c",
            "a158a2efd3c547eca2b126c119e9af29",
            "39d57ffde15e47f18ef70e4bee3af485",
            "a8287a4945c246e8b7b135da3d430c30"
          ]
        },
        "id": "CwBRIVJGm6tM",
        "outputId": "ee184179-aa40-4bb7-b120-aaf87c91be80"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51e9c784a63744468d400699f01ded6c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "### 2.4 - Evaluate the Model Quantitatively (with ROUGE Metric)\n",
        "\n",
        "rouge = evaluate.load('rouge')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "tags": [],
        "ExecuteTime": {
          "end_time": "2023-07-07T13:00:46.327007600Z",
          "start_time": "2023-07-07T13:00:36.138406800Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "TlCpwgvUm6tN",
        "outputId": "1e5e7c8d-b24c-41de-b1b0-22b018747c85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            human_baseline_summaries  \\\n",
              "0  Ms. Dawson helps #Person1# to write a memo to ...   \n",
              "1  In order to prevent employees from wasting tim...   \n",
              "2  Ms. Dawson takes a dictation for #Person1# abo...   \n",
              "3  #Person2# arrives late because of traffic jam....   \n",
              "4  #Person2# decides to follow #Person1#'s sugges...   \n",
              "5  #Person2# complains to #Person1# about the tra...   \n",
              "6  #Person1# tells Kate that Masha and Hero get d...   \n",
              "7  #Person1# tells Kate that Masha and Hero are g...   \n",
              "8  #Person1# and Kate talk about the divorce betw...   \n",
              "9  #Person1# and Brian are at the birthday party ...   \n",
              "\n",
              "                            original_model_summaries  \\\n",
              "0  This memo is to be distributed to all employee...   \n",
              "1  This memo is to be distributed to all employee...   \n",
              "2  This memo is to be distributed to all employee...   \n",
              "3    Taking public transport to work is a good idea.   \n",
              "4    Taking public transport to work is a good idea.   \n",
              "5    Taking public transport to work is a good idea.   \n",
              "6               Masha and Hero are getting divorced.   \n",
              "7               Masha and Hero are getting divorced.   \n",
              "8               Masha and Hero are getting divorced.   \n",
              "9                     Brian's birthday is coming up.   \n",
              "\n",
              "                            instruct_model_summaries  \n",
              "0  #Person1# asks Ms. Dawson to take a dictation ...  \n",
              "1  #Person1# asks Ms. Dawson to take a dictation ...  \n",
              "2  #Person1# asks Ms. Dawson to take a dictation ...  \n",
              "3  #Person2# got stuck in traffic again. #Person1...  \n",
              "4  #Person2# got stuck in traffic again. #Person1...  \n",
              "5  #Person2# got stuck in traffic again. #Person1...  \n",
              "6  Masha and Hero are getting divorced. Kate can'...  \n",
              "7  Masha and Hero are getting divorced. Kate can'...  \n",
              "8  Masha and Hero are getting divorced. Kate can'...  \n",
              "9  Brian's birthday is coming. #Person1# invites ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8be47333-255a-4ab9-9058-bfa5b83e3856\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human_baseline_summaries</th>\n",
              "      <th>original_model_summaries</th>\n",
              "      <th>instruct_model_summaries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ms. Dawson helps #Person1# to write a memo to ...</td>\n",
              "      <td>This memo is to be distributed to all employee...</td>\n",
              "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In order to prevent employees from wasting tim...</td>\n",
              "      <td>This memo is to be distributed to all employee...</td>\n",
              "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ms. Dawson takes a dictation for #Person1# abo...</td>\n",
              "      <td>This memo is to be distributed to all employee...</td>\n",
              "      <td>#Person1# asks Ms. Dawson to take a dictation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#Person2# arrives late because of traffic jam....</td>\n",
              "      <td>Taking public transport to work is a good idea.</td>\n",
              "      <td>#Person2# got stuck in traffic again. #Person1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#Person2# decides to follow #Person1#'s sugges...</td>\n",
              "      <td>Taking public transport to work is a good idea.</td>\n",
              "      <td>#Person2# got stuck in traffic again. #Person1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>#Person2# complains to #Person1# about the tra...</td>\n",
              "      <td>Taking public transport to work is a good idea.</td>\n",
              "      <td>#Person2# got stuck in traffic again. #Person1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>#Person1# tells Kate that Masha and Hero get d...</td>\n",
              "      <td>Masha and Hero are getting divorced.</td>\n",
              "      <td>Masha and Hero are getting divorced. Kate can'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>#Person1# tells Kate that Masha and Hero are g...</td>\n",
              "      <td>Masha and Hero are getting divorced.</td>\n",
              "      <td>Masha and Hero are getting divorced. Kate can'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>#Person1# and Kate talk about the divorce betw...</td>\n",
              "      <td>Masha and Hero are getting divorced.</td>\n",
              "      <td>Masha and Hero are getting divorced. Kate can'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>#Person1# and Brian are at the birthday party ...</td>\n",
              "      <td>Brian's birthday is coming up.</td>\n",
              "      <td>Brian's birthday is coming. #Person1# invites ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8be47333-255a-4ab9-9058-bfa5b83e3856')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8be47333-255a-4ab9-9058-bfa5b83e3856 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8be47333-255a-4ab9-9058-bfa5b83e3856');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "dialogues = dataset['test'][0:10]['dialogue']\n",
        "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "\n",
        "for _, dialogue in enumerate(dialogues):\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
        "\n",
        "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    original_model_summaries.append(original_model_text_output)\n",
        "\n",
        "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "    instruct_model_summaries.append(instruct_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "YE-7TZdjm6tO"
      },
      "source": [
        "Evaluate the models computing ROUGE metrics. Notice the improvement in the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KBYpTD2m6tO",
        "outputId": "451688dc-b290-41b3-8e85-a78377e66646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.28647748040489973, 'rouge2': 0.13497482028216662, 'rougeL': 0.23619027925479535, 'rougeLsum': 0.23930701616185485}\n",
            "INSTRUCT MODEL:\n",
            "{'rouge1': 0.41026607717457186, 'rouge2': 0.17840645241958838, 'rougeL': 0.2977022096267017, 'rougeLsum': 0.2987374187518165}\n"
          ]
        }
      ],
      "source": [
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEC5S-A_m6tO"
      },
      "source": [
        "The file `data/dialogue-summary-training-results.csv` contains a pre-populated list of all model results which you can use to evaluate on a larger section of data. Let's do that for each of the models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "5LjoQ0fpm6tO"
      },
      "outputs": [],
      "source": [
        "results = pd.read_csv(\"data/dialogue-summary-training-results.csv\")\n",
        "\n",
        "human_baseline_summaries = results['human_baseline_summaries'].values\n",
        "original_model_summaries = results['original_model_summaries'].values\n",
        "instruct_model_summaries = results['instruct_model_summaries'].values\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "iCHxG6R1m6tO"
      },
      "source": [
        "The results show substantial improvement in all ROUGE metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "k5ilFDVSm6tO"
      },
      "outputs": [],
      "source": [
        "print(\"Absolute percentage improvement of INSTRUCT MODEL over HUMAN BASELINE\")\n",
        "\n",
        "improvement = (np.array(list(instruct_model_results.values())) - np.array(list(original_model_results.values())))\n",
        "for key, value in zip(instruct_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii8grGuWm6tP"
      },
      "source": [
        "<a name='3'></a>\n",
        "## 3 - Perform Parameter Efficient Fine-Tuning (PEFT)\n",
        "\n",
        "Now, let's perform **Parameter Efficient Fine-Tuning (PEFT)** fine-tuning as opposed to \"full fine-tuning\" as you did above. PEFT is a form of instruction fine-tuning that is much more efficient than full fine-tuning - with comparable evaluation results as you will see soon.\n",
        "\n",
        "PEFT is a generic term that includes **Low-Rank Adaptation (LoRA)** and prompt tuning (which is NOT THE SAME as prompt engineering!). In most cases, when someone says PEFT, they typically mean LoRA. LoRA, at a very high level, allows the user to fine-tune their model using fewer compute resources (in some cases, a single GPU). After fine-tuning for a specific task, use case, or tenant with LoRA, the result is that the original LLM remains unchanged and a newly-trained “LoRA adapter” emerges. This LoRA adapter is much, much smaller than the original LLM - on the order of a single-digit % of the original LLM size (MBs vs GBs).  \n",
        "\n",
        "That said, at inference time, the LoRA adapter needs to be reunited and combined with its original LLM to serve the inference request.  The benefit, however, is that many LoRA adapters can re-use the original LLM which reduces overall memory requirements when serving multiple tasks and use cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w73Wgc-lm6tP"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "### 3.1 - Setup the PEFT/LoRA model for Fine-Tuning\n",
        "\n",
        "You need to set up the PEFT/LoRA model for fine-tuning with a new layer/parameter adapter. Using PEFT/LoRA, you are freezing the underlying LLM and only training the adapter. Have a look at the LoRA configuration below. Note the rank (`r`) hyper-parameter, which defines the rank/dimension of the adapter to be trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "4_2GMioSm6tP"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=32, # Rank\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "VcrgjLkBm6tP"
      },
      "source": [
        "Add LoRA adapter layers/parameters to the original LLM to be trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "TXRMYd--m6tP"
      },
      "outputs": [],
      "source": [
        "peft_model = get_peft_model(original_model,\n",
        "                            lora_config)\n",
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "KXYA9_rLm6tQ"
      },
      "source": [
        "<a name='3.2'></a>\n",
        "### 3.2 - Train PEFT Adapter\n",
        "\n",
        "Define training arguments and create `Trainer` instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ORM6hnXnm6tQ"
      },
      "outputs": [],
      "source": [
        "output_dir = f'../tmp/peft-dialogue-summary-training-{str(int(time.time()))}'\n",
        "\n",
        "peft_training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    auto_find_batch_size=True,\n",
        "    learning_rate=1e-3, # Higher learning rate than full fine-tuning.\n",
        "    num_train_epochs=1,\n",
        "    logging_steps=1,\n",
        "    max_steps=1\n",
        ")\n",
        "\n",
        "peft_trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=peft_training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6fo5XNfm6tQ"
      },
      "source": [
        "Now everything is ready to train the PEFT adapter and save the model.\n",
        "\n",
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSIxMjUiIHZpZXdCb3g9IjAgMCA4MDAgMTI1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogICAgPGRlZnM+CiAgICAgICAgPGxpbmVhckdyYWRpZW50IGlkPSJmYWRlR3JhZGllbnQiIHgxPSIwIiB4Mj0iMSI+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMCUiIHN0b3AtY29sb3I9IiNGMEYwRjAiLz4KICAgICAgICAgICAgPHN0b3Agb2Zmc2V0PSIxMDAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIiBzdG9wLW9wYWNpdHk9IjAiLz4KICAgICAgICA8L2xpbmVhckdyYWRpZW50PgogICAgICAgIDxtYXNrIGlkPSJmYWRlTWFzayI+CiAgICAgICAgICAgIDxyZWN0IHg9IjAiIHk9IjAiIHdpZHRoPSI3NTAiIGhlaWdodD0iMTI1IiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSIxMjUiIGZpbGw9InVybCgjZmFkZUdyYWRpZW50KSIvPgogICAgICAgIDwvbWFzaz4KICAgIDwvZGVmcz4KICAgIDxwYXRoIGQ9Ik0zLDUwIEE1MCw1MCAwIDAgMSA1MywzIEw3OTcsMyBMNzk3LDk3IEw5Nyw5NyBMNTAsMTE1IEwzLDk3IFoiIGZpbGw9IiNGMEYwRjAiIHN0cm9rZT0iI0UwRTBFMCIgc3Ryb2tlLXdpZHRoPSIxIiBtYXNrPSJ1cmwoI2ZhZGVNYXNrKSIvPgogICAgPGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iMzAiIGZpbGw9IiM1N2M0ZjgiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIxIi8+CiAgICA8Y2lyY2xlIGN4PSI1MCIgY3k9IjUwIiByPSIyNSIgZmlsbD0iI0YwRjBGMCIvPgogICAgPGxpbmUgeDE9IjUwIiB5MT0iNTAiIHgyPSI1MCIgeTI9IjMwIiBzdHJva2U9IiM1N2M0ZjgiIHN0cm9rZS13aWR0aD0iMyIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIi8+CiAgICA8bGluZSB4MT0iNTAiIHkxPSI1MCIgeDI9IjY1IiB5Mj0iNTAiIHN0cm9rZT0iIzU3YzRmOCIgc3Ryb2tlLXdpZHRoPSIzIiBzdHJva2UtbGluZWNhcD0icm91bmQiLz4KICAgIDx0ZXh0IHg9IjEwMCIgeT0iMzQiIGZvbnQtZmFtaWx5PSJBcmlhbCwgc2Fucy1zZXJpZiIgZm9udC1zaXplPSIxNCIgZmlsbD0iIzMzMzMzMyI+VGhlIG5leHQgY2VsbCBtYXkgdGFrZSBhIGZldyBtaW51dGVzIHRvIHJ1bi48L3RleHQ+Cjwvc3ZnPgo=\" alt=\"Time alert open medium\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "2_8IrMbsm6tQ"
      },
      "outputs": [],
      "source": [
        "peft_trainer.train()\n",
        "\n",
        "peft_model_path=\"../tmp/peft-dialogue-summary-checkpoint-local\"\n",
        "\n",
        "peft_trainer.model.save_pretrained(peft_model_path)\n",
        "tokenizer.save_pretrained(peft_model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "oOnEP578m6tT"
      },
      "source": [
        "<img src=\"data:image/svg+xml;base64,Cjxzdmcgd2lkdGg9IjgwMCIgaGVpZ2h0PSI1MCIgdmlld0JveD0iMCAwIDgwMCA1MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCBpZD0iZmFkZUdyYWRpZW50IiB4MT0iMCIgeDI9IjEiPgogICAgICAgICAgICA8c3RvcCBvZmZzZXQ9IjAlIiBzdG9wLWNvbG9yPSIjRjBGMEYwIi8+CiAgICAgICAgICAgIDxzdG9wIG9mZnNldD0iMTAwJSIgc3RvcC1jb2xvcj0iI0YwRjBGMCIgc3RvcC1vcGFjaXR5PSIwIi8+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgICAgICA8bWFzayBpZD0iZmFkZU1hc2siPgogICAgICAgICAgICA8cmVjdCB4PSIwIiB5PSIwIiB3aWR0aD0iNzUwIiBoZWlnaHQ9IjUwIiBmaWxsPSJ3aGl0ZSIvPgogICAgICAgICAgICA8cmVjdCB4PSI3NTAiIHk9IjAiIHdpZHRoPSI1MCIgaGVpZ2h0PSI1MCIgZmlsbD0idXJsKCNmYWRlR3JhZGllbnQpIi8+CiAgICAgICAgPC9tYXNrPgogICAgPC9kZWZzPgogICAgPHBhdGggZD0iTTI1LDUwIFEwLDUwIDAsMjUgTDUwLDMgTDk3LDI1IEw3OTcsMjUgTDc5Nyw1MCBMMjUsNTAgWiIgZmlsbD0iI0YwRjBGMCIgc3Ryb2tlPSIjRTBFMEUwIiBzdHJva2Utd2lkdGg9IjEiIG1hc2s9InVybCgjZmFkZU1hc2spIi8+Cjwvc3ZnPgo=\" alt=\"Time alert close\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "s1skHZ2wm6td"
      },
      "source": [
        "That training was performed on a subset of data. To load a fully trained PEFT model, read a checkpoint of a PEFT model from S3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "1l4yiX4hm6td"
      },
      "outputs": [],
      "source": [
        "!aws s3 cp --recursive s3://dlai-generative-ai/models/peft-dialogue-summary-checkpoint/ ../tmp/peft-dialogue-summary-checkpoint-from-s3/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "H7STtGbSm6td"
      },
      "source": [
        "Check that the size of this model is much less than the original LLM:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "K0l8JJflm6te"
      },
      "outputs": [],
      "source": [
        "!ls -al ../tmp/peft-dialogue-summary-checkpoint-from-s3/adapter_model.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "G7_nfD1km6te"
      },
      "source": [
        "Prepare this model by adding an adapter to the original FLAN-T5 model. You are setting `is_trainable=False` because the plan is only to perform inference with this PEFT model. If you were preparing the model for further training, you would set `is_trainable=True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "bBfutXFsm6te"
      },
      "outputs": [],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "peft_model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "\n",
        "peft_model = PeftModel.from_pretrained(peft_model_base,\n",
        "                                       '../tmp/peft-dialogue-summary-checkpoint-from-s3/',\n",
        "                                       torch_dtype=torch.bfloat16,\n",
        "                                       is_trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "Ho5qzl4_m6te"
      },
      "source": [
        "The number of trainable parameters will be `0` due to `is_trainable=False` setting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "90E9BCK_m6te"
      },
      "outputs": [],
      "source": [
        "print(print_number_of_trainable_model_parameters(peft_model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZxmWs4wm6tf"
      },
      "source": [
        "<a name='3.3'></a>\n",
        "### 3.3 - Evaluate the Model Qualitatively (Human Evaluation)\n",
        "\n",
        "Make inferences for the same example as in sections [1.3](#1.3) and [2.3](#2.3), with the original model, fully fine-tuned and PEFT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Yz80Whmvm6tf"
      },
      "outputs": [],
      "source": [
        "index = 200\n",
        "dialogue = dataset['test'][index]['dialogue']\n",
        "baseline_human_summary = dataset['test'][index]['summary']\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{human_baseline_summary}')\n",
        "print(dash_line)\n",
        "print(f'ORIGINAL MODEL:\\n{original_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'INSTRUCT MODEL:\\n{instruct_model_text_output}')\n",
        "print(dash_line)\n",
        "print(f'PEFT MODEL: {peft_model_text_output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwNrqc-om6tf"
      },
      "source": [
        "<a name='3.4'></a>\n",
        "### 3.4 - Evaluate the Model Quantitatively (with ROUGE Metric)\n",
        "Perform inferences for the sample of the test dataset (only 10 dialogues and summaries to save time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "zdKrv4iim6tf"
      },
      "outputs": [],
      "source": [
        "dialogues = dataset['test'][0:10]['dialogue']\n",
        "human_baseline_summaries = dataset['test'][0:10]['summary']\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "peft_model_summaries = []\n",
        "\n",
        "for idx, dialogue in enumerate(dialogues):\n",
        "    prompt = f\"\"\"\n",
        "Summarize the following conversation.\n",
        "\n",
        "{dialogue}\n",
        "\n",
        "Summary: \"\"\"\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    human_baseline_text_output = human_baseline_summaries[idx]\n",
        "\n",
        "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    instruct_model_outputs = instruct_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    instruct_model_text_output = tokenizer.decode(instruct_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    original_model_summaries.append(original_model_text_output)\n",
        "    instruct_model_summaries.append(instruct_model_text_output)\n",
        "    peft_model_summaries.append(peft_model_text_output)\n",
        "\n",
        "zipped_summaries = list(zip(human_baseline_summaries, original_model_summaries, instruct_model_summaries, peft_model_summaries))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_summaries', 'original_model_summaries', 'instruct_model_summaries', 'peft_model_summaries'])\n",
        "df"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "WTJrReI7m6tg"
      },
      "source": [
        "Compute ROUGE score for this subset of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "M3fh_iMkm6tg"
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "peft_model_results = rouge.compute(\n",
        "    predictions=peft_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)\n",
        "print('PEFT MODEL:')\n",
        "print(peft_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upxo0lGEm6tg"
      },
      "source": [
        "Notice, that PEFT model results are not too bad, while the training process was much easier!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mk6Qpko6m6tg"
      },
      "source": [
        "You already computed ROUGE score on the full dataset, after loading the results from the `data/dialogue-summary-training-results.csv` file. Load the values for the PEFT model now and check its performance compared to other models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ysPBzmwgm6tg"
      },
      "outputs": [],
      "source": [
        "human_baseline_summaries = results['human_baseline_summaries'].values\n",
        "original_model_summaries = results['original_model_summaries'].values\n",
        "instruct_model_summaries = results['instruct_model_summaries'].values\n",
        "peft_model_summaries     = results['peft_model_summaries'].values\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "peft_model_results = rouge.compute(\n",
        "    predictions=peft_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)\n",
        "print('PEFT MODEL:')\n",
        "print(peft_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMcjlgxim6th"
      },
      "source": [
        "The results show less of an improvement over full fine-tuning, but the benefits of PEFT typically outweigh the slightly-lower performance metrics.\n",
        "\n",
        "Calculate the improvement of PEFT over the original model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "jeUI47Zim6th"
      },
      "outputs": [],
      "source": [
        "print(\"Absolute percentage improvement of PEFT MODEL over HUMAN BASELINE\")\n",
        "\n",
        "improvement = (np.array(list(peft_model_results.values())) - np.array(list(original_model_results.values())))\n",
        "for key, value in zip(peft_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwMGtxnZm6th"
      },
      "source": [
        "Now calculate the improvement of PEFT over a full fine-tuned model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "2ZuOLG1dm6th"
      },
      "outputs": [],
      "source": [
        "print(\"Absolute percentage improvement of PEFT MODEL over INSTRUCT MODEL\")\n",
        "\n",
        "improvement = (np.array(list(peft_model_results.values())) - np.array(list(instruct_model_results.values())))\n",
        "for key, value in zip(peft_model_results.keys(), improvement):\n",
        "    print(f'{key}: {value*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwC5vHnwm6th"
      },
      "source": [
        "Here you see a small percentage decrease in the ROUGE metrics vs. full fine-tuned. However, the training requires much less computing and memory resources (often just a single GPU)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_C6soNXm6ti"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "availableInstances": [
      {
        "_defaultOrder": 0,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.t3.medium",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 1,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.t3.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 2,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.t3.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 3,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.t3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 4,
        "_isFastLaunch": true,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 5,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 6,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 7,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 8,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 9,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 10,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 11,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 12,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.m5d.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 13,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.m5d.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 14,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.m5d.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 15,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.m5d.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 16,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.m5d.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 17,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.m5d.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 18,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.m5d.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 19,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.m5d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 20,
        "_isFastLaunch": false,
        "category": "General purpose",
        "gpuNum": 0,
        "hideHardwareSpecs": true,
        "memoryGiB": 0,
        "name": "ml.geospatial.interactive",
        "supportedImageNames": [
          "sagemaker-geospatial-v1-0"
        ],
        "vcpuNum": 0
      },
      {
        "_defaultOrder": 21,
        "_isFastLaunch": true,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 4,
        "name": "ml.c5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 22,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 8,
        "name": "ml.c5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 23,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.c5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 24,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.c5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 25,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 72,
        "name": "ml.c5.9xlarge",
        "vcpuNum": 36
      },
      {
        "_defaultOrder": 26,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 96,
        "name": "ml.c5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 27,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 144,
        "name": "ml.c5.18xlarge",
        "vcpuNum": 72
      },
      {
        "_defaultOrder": 28,
        "_isFastLaunch": false,
        "category": "Compute optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.c5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 29,
        "_isFastLaunch": true,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g4dn.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 30,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g4dn.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 31,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g4dn.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 32,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g4dn.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 33,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g4dn.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 34,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g4dn.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 35,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 61,
        "name": "ml.p3.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 36,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 244,
        "name": "ml.p3.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 37,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 488,
        "name": "ml.p3.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 38,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.p3dn.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 39,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.r5.large",
        "vcpuNum": 2
      },
      {
        "_defaultOrder": 40,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.r5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 41,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.r5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 42,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.r5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 43,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.r5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 44,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.r5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 45,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 512,
        "name": "ml.r5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 46,
        "_isFastLaunch": false,
        "category": "Memory Optimized",
        "gpuNum": 0,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.r5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 47,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 16,
        "name": "ml.g5.xlarge",
        "vcpuNum": 4
      },
      {
        "_defaultOrder": 48,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 32,
        "name": "ml.g5.2xlarge",
        "vcpuNum": 8
      },
      {
        "_defaultOrder": 49,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 64,
        "name": "ml.g5.4xlarge",
        "vcpuNum": 16
      },
      {
        "_defaultOrder": 50,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 128,
        "name": "ml.g5.8xlarge",
        "vcpuNum": 32
      },
      {
        "_defaultOrder": 51,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 1,
        "hideHardwareSpecs": false,
        "memoryGiB": 256,
        "name": "ml.g5.16xlarge",
        "vcpuNum": 64
      },
      {
        "_defaultOrder": 52,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 192,
        "name": "ml.g5.12xlarge",
        "vcpuNum": 48
      },
      {
        "_defaultOrder": 53,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 4,
        "hideHardwareSpecs": false,
        "memoryGiB": 384,
        "name": "ml.g5.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 54,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 768,
        "name": "ml.g5.48xlarge",
        "vcpuNum": 192
      },
      {
        "_defaultOrder": 55,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4d.24xlarge",
        "vcpuNum": 96
      },
      {
        "_defaultOrder": 56,
        "_isFastLaunch": false,
        "category": "Accelerated computing",
        "gpuNum": 8,
        "hideHardwareSpecs": false,
        "memoryGiB": 1152,
        "name": "ml.p4de.24xlarge",
        "vcpuNum": 96
      }
    ],
    "colab": {
      "name": "Fine-tune a language model",
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "instance_type": "ml.m5.2xlarge",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a80a5944e70b47998d8c2c69d507921a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6dac7c8662d04bb4974f6157fe68427a",
              "IPY_MODEL_11fad3b120ba455fb5b5ecba576e3a8f",
              "IPY_MODEL_93b879cce4c24f00a0de09ae8c1feced"
            ],
            "layout": "IPY_MODEL_3bb5513122d14d5396f7074b824402f2"
          }
        },
        "6dac7c8662d04bb4974f6157fe68427a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d463498bbb7f47deacc5d628ddf9dd5b",
            "placeholder": "​",
            "style": "IPY_MODEL_6148f855b94b46dc9b4eff88c3652667",
            "value": "100%"
          }
        },
        "11fad3b120ba455fb5b5ecba576e3a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98212a0d70a847b1a38f4f86efef6de8",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b85fe06196784b1e8cbb69cb65086104",
            "value": 3
          }
        },
        "93b879cce4c24f00a0de09ae8c1feced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06fd29c11bb54b23acd134d5ca525ab6",
            "placeholder": "​",
            "style": "IPY_MODEL_5ceea9750bb841c5b6913ad2eeaf2c4e",
            "value": " 3/3 [00:00&lt;00:00, 174.84it/s]"
          }
        },
        "3bb5513122d14d5396f7074b824402f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d463498bbb7f47deacc5d628ddf9dd5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6148f855b94b46dc9b4eff88c3652667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98212a0d70a847b1a38f4f86efef6de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85fe06196784b1e8cbb69cb65086104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06fd29c11bb54b23acd134d5ca525ab6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ceea9750bb841c5b6913ad2eeaf2c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1905cbfeba94648a6816ccdcda2539d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10120c8d4f7747489b8bee628a6f0180",
              "IPY_MODEL_3e7c8e3218a944c0ac5021caaefdb3e3",
              "IPY_MODEL_6a1a33a0d7604720896e567fa2c36da9"
            ],
            "layout": "IPY_MODEL_d6c48827c43b491194074d2d10e07ff3"
          }
        },
        "10120c8d4f7747489b8bee628a6f0180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_846a9f9375714f8bb3947d38043e57b2",
            "placeholder": "​",
            "style": "IPY_MODEL_9b316cc6529d461ca32abb338ec28c79",
            "value": "Map: 100%"
          }
        },
        "3e7c8e3218a944c0ac5021caaefdb3e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2df8a35554ac42e58c86e933004dd89a",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19b8ca77eb1148c99a6c9e162971c75b",
            "value": 500
          }
        },
        "6a1a33a0d7604720896e567fa2c36da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6806574fdfd142218e10aa8f0af9f6df",
            "placeholder": "​",
            "style": "IPY_MODEL_3dacaf711bfe4e78aefc6b9068aead27",
            "value": " 500/500 [00:00&lt;00:00, 1621.46 examples/s]"
          }
        },
        "d6c48827c43b491194074d2d10e07ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "846a9f9375714f8bb3947d38043e57b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b316cc6529d461ca32abb338ec28c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2df8a35554ac42e58c86e933004dd89a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19b8ca77eb1148c99a6c9e162971c75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6806574fdfd142218e10aa8f0af9f6df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dacaf711bfe4e78aefc6b9068aead27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5e8bdb631104c33819e67c1ee42a518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0eed6a8588af41de9ec91529c13b632f",
              "IPY_MODEL_321855886b85445d9265ee49f2355001",
              "IPY_MODEL_294002bae48d44598a363feefcb8ca0f"
            ],
            "layout": "IPY_MODEL_138c7319791e40ecb395946335750273"
          }
        },
        "0eed6a8588af41de9ec91529c13b632f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e927e12403de49d2987b698c09015fe0",
            "placeholder": "​",
            "style": "IPY_MODEL_d85dcc81576c4c8daa7937c7ea0ccd74",
            "value": "Filter: 100%"
          }
        },
        "321855886b85445d9265ee49f2355001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c479f85c004f4cba9d4263d1e6a4f728",
            "max": 12460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f4f2adc3c7247b7b1e5683fd9662358",
            "value": 12460
          }
        },
        "294002bae48d44598a363feefcb8ca0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca983f28c718468c8a1460f4a9515069",
            "placeholder": "​",
            "style": "IPY_MODEL_c2bba51ae57246ad8ddb69a84de6d400",
            "value": " 12460/12460 [00:05&lt;00:00, 2403.83 examples/s]"
          }
        },
        "138c7319791e40ecb395946335750273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "e927e12403de49d2987b698c09015fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d85dcc81576c4c8daa7937c7ea0ccd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c479f85c004f4cba9d4263d1e6a4f728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f4f2adc3c7247b7b1e5683fd9662358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca983f28c718468c8a1460f4a9515069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2bba51ae57246ad8ddb69a84de6d400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51e9c784a63744468d400699f01ded6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b95c132c45954556958b01c44dc2b92a",
              "IPY_MODEL_dca1e8e2c5f543fbb80abca2b8810c2b",
              "IPY_MODEL_c5608521c86b48138969e037d8e73b2b"
            ],
            "layout": "IPY_MODEL_ac70795e1b0e413787935c111bfad60f"
          }
        },
        "b95c132c45954556958b01c44dc2b92a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_363ce6cf8f9a4dc2abf6819fe889d77c",
            "placeholder": "​",
            "style": "IPY_MODEL_0eef781b94df4adbb8b8cffbeb9814da",
            "value": "Downloading builder script: 100%"
          }
        },
        "dca1e8e2c5f543fbb80abca2b8810c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c38b56d469e549b7932e10fad13e109c",
            "max": 6270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a158a2efd3c547eca2b126c119e9af29",
            "value": 6270
          }
        },
        "c5608521c86b48138969e037d8e73b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39d57ffde15e47f18ef70e4bee3af485",
            "placeholder": "​",
            "style": "IPY_MODEL_a8287a4945c246e8b7b135da3d430c30",
            "value": " 6.27k/6.27k [00:00&lt;00:00, 529kB/s]"
          }
        },
        "ac70795e1b0e413787935c111bfad60f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363ce6cf8f9a4dc2abf6819fe889d77c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eef781b94df4adbb8b8cffbeb9814da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c38b56d469e549b7932e10fad13e109c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a158a2efd3c547eca2b126c119e9af29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39d57ffde15e47f18ef70e4bee3af485": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8287a4945c246e8b7b135da3d430c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}